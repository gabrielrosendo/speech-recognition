{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMJTi17PTa9aZdFNlDVrAr7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["https://docs.opencv.org/2.4/modules/contrib/doc/facerec/facerec_tutorial.html"],"metadata":{"id":"wa3ntf7U6OrI"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-DAHf9hnZBeR","executionInfo":{"status":"ok","timestamp":1727741061090,"user_tz":420,"elapsed":7037,"user":{"displayName":"Tejaswi Chintapalli","userId":"03963810696295408727"}},"outputId":"2c09d68b-7ecc-4193-e074-1398950e7667"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-contrib-python) (1.26.4)\n"]}],"source":["!pip install opencv-contrib-python"]},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","from google.colab.patches import cv2_imshow"],"metadata":{"id":"71PS_4HVZEdB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize the recognizer\n","recognizer = cv2.face.LBPHFaceRecognizer_create(radius=1, neighbors=10, grid_x=8, grid_y=8)"],"metadata":{"id":"r_5Lcaq5ZZmD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Image paths (ensure these are correct)\n","imagePaths = '/content/Singers'"],"metadata":{"id":"633lhNBsZcYz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the face cascade\n","faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"],"metadata":{"id":"jDAfWo1dZegJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = []\n","ids = []\n","count = 0\n","label_dict = {}  # Dictionary to store labels and corresponding ids\n","\n","\n","# Loop over the image paths\n","for imageName in os.listdir(imagePaths):\n","\n","    # Construct the full image path\n","    imagePath = os.path.join(imagePaths, imageName)\n","\n","    # Read the image\n","    image = cv2.imread(imagePath)\n","\n","    # Check if the image was loaded successfully\n","    if image is None:\n","        print(f\"Error: Unable to load image {imagePath}. Skipping...\")\n","        continue\n","\n","\n","\n","    # Convert the image to grayscale\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","    # Detect faces in the image\n","    faces = faceCascade.detectMultiScale(\n","        gray,\n","        scaleFactor=1.1,\n","        minNeighbors=3,\n","        minSize=(30, 30)\n","    )\n","\n","    # Process the detected faces\n","    for (x, y, w, h) in faces:\n","        # Extract the face ROI and append it to the training set\n","        X.append(gray[y:y+h, x:x+w])\n","        label = os.path.split(imagePath)[-1].split('.')[0]\n","        ids.append(count)\n","        label_dict[label] = count\n","        print(label_dict)\n","        print(ids)\n","        break  # Break after the first face is detected in each image\n","    count += 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TgK-yre-Zgkg","executionInfo":{"status":"ok","timestamp":1727745612539,"user_tz":420,"elapsed":1779,"user":{"displayName":"Tejaswi Chintapalli","userId":"03963810696295408727"}},"outputId":"9f3b58b6-e57d-4a5d-ff04-f7b8c132e10d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'Weekend': 0}\n","[0]\n","{'Weekend': 0, 'Ariana': 1}\n","[0, 1]\n","{'Weekend': 0, 'Ariana': 1, 'Harry': 2}\n","[0, 1, 2]\n","{'Weekend': 0, 'Ariana': 1, 'Harry': 2, 'Taylor': 3}\n","[0, 1, 2, 3]\n","{'Weekend': 0, 'Ariana': 1, 'Harry': 2, 'Taylor': 3, 'Shawn': 4}\n","[0, 1, 2, 3, 4]\n","{'Weekend': 0, 'Ariana': 1, 'Harry': 2, 'Taylor': 3, 'Shawn': 4, 'Charlie': 5}\n","[0, 1, 2, 3, 4, 5]\n","{'Weekend': 0, 'Ariana': 1, 'Harry': 2, 'Taylor': 3, 'Shawn': 4, 'Charlie': 5, 'Justin': 6}\n","[0, 1, 2, 3, 4, 5, 6]\n","{'Weekend': 0, 'Ariana': 1, 'Harry': 2, 'Taylor': 3, 'Shawn': 4, 'Charlie': 5, 'Justin': 6, 'Selena': 7}\n","[0, 1, 2, 3, 4, 5, 6, 7]\n","{'Weekend': 0, 'Ariana': 1, 'Harry': 2, 'Taylor': 3, 'Shawn': 4, 'Charlie': 5, 'Justin': 6, 'Selena': 7, 'Nicki': 8}\n","[0, 1, 2, 3, 4, 5, 6, 7, 8]\n","{'Weekend': 0, 'Ariana': 1, 'Harry': 2, 'Taylor': 3, 'Shawn': 4, 'Charlie': 5, 'Justin': 6, 'Selena': 7, 'Nicki': 8, 'cardib': 9}\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"]}]},{"cell_type":"code","source":["# Train the recognizer\n","recognizer.train(X, np.array(ids))"],"metadata":{"id":"oub-HkX8ZkD9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save the trained model\n","recognizer.save('cvtraining.yml')"],"metadata":{"id":"bGEO4VznZlZC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Testing"],"metadata":{"id":"A9NQaKOhd3DJ"}},{"cell_type":"code","source":["recognizer.read('cvtraining.yml')"],"metadata":{"id":"aowq0D9Ad6AG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["testpath = \"Selena.jpeg\""],"metadata":{"id":"GOG-a_b8rDtJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["testpath = \"test.webp\""],"metadata":{"id":"bwp7U-q6d-pD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["testpath = \"test.jpg\""],"metadata":{"id":"CY6ZvnlLuxCU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Read the test image\n","image = cv2.imread(testpath)\n"],"metadata":{"id":"LzYEb5WbeSd3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert the image to grayscale\n","gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"],"metadata":{"id":"trwMFhjKeclT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert to numpy array for face detection\n","img_numpy = np.array(gray, 'uint8')"],"metadata":{"id":"KIa0Ym7Bed3W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Detect faces in the image\n","faces = faceCascade.detectMultiScale(\n","    img_numpy,\n","    scaleFactor=1.1,\n","    minNeighbors=10,\n","    minSize=(30, 30)\n",")"],"metadata":{"id":"jjkg40NXeg9g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Loop through the detected faces and predict using the recognizer\n","for (x, y, w, h) in faces:\n","    # Predict the label (ID) and confidence of the detected face\n","    id, confidence = recognizer.predict(gray[y:y+h, x:x+w])\n","    name = [key for key, value in label_dict.items() if value == id]\n","    print(f\"Predicted ID: {id}\")\n","    print(f\"Predicted name: {name}\")\n","    print(f\"Confidence: {confidence}\")\n","\n","    # Draw a rectangle around the detected face (optional, for visualization)\n","    cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n","    cv2.rectangle(image, (x, y + h - 35), (x + w, y + h), (255, 0, 0), cv2.FILLED)\n","    font = cv2.FONT_HERSHEY_DUPLEX\n","    cv2.putText(image, name[0], (x + 6, y + h - 6), font, 1.0, (0, 0, 0), 1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e0owsiPReiaQ","executionInfo":{"status":"ok","timestamp":1727746774506,"user_tz":420,"elapsed":171,"user":{"displayName":"Tejaswi Chintapalli","userId":"03963810696295408727"}},"outputId":"2bf1a151-549c-4eca-bd3b-b2cc098498e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted ID: 9\n","Predicted name: ['cardib']\n","Confidence: 37.79545541688728\n"]}]},{"cell_type":"code","source":["# Display the image with the detected face and drawn rectangle\n","cv2_imshow(image)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1urchSamtN6LOaTXtDsK5cSuALhyx5uwr"},"id":"9H6T1YR8em1m","executionInfo":{"status":"ok","timestamp":1727746787041,"user_tz":420,"elapsed":4232,"user":{"displayName":"Tejaswi Chintapalli","userId":"03963810696295408727"}},"outputId":"e978a8a9-aa73-48a8-90ec-7664ce9b9541"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}